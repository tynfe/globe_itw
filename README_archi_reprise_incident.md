üèóÔ∏è Architecture Flow 

üìã Vue d'ensemble  
Ce document d√©crit le flow complet de notre pipeline de matching entre deux sources de donn√©es magasins (GI et TH), avec un syst√®me d'auto-healing pour corriger les incoh√©rences d√©tect√©es.

üîÑ Flow d√©taill√© - Step by Step
Step 1Ô∏è‚É£ : User DBT - Initialisation du projet  
Qui : Data Engineer Quoi : Le Data Engineer initialise le projet dbt en clonant le repository et en configurant son environnement de travail local.
Il v√©rifie que la connexion √† Snowflake fonctionne correctement.  
Pourquoi : C'est le point de d√©part pour pouvoir d√©velopper les mod√®les de matching. Sans cette √©tape, impossible de travailler sur les transformations.  
R√©sultat : Environnement dbt op√©rationnel, le DE peut commencer √† coder ses mod√®les.         

Step 2Ô∏è‚É£ : Cr√©ation de DDL avec Terraform et GitHub action   
Qui : Platform (Airflow operator trigger action github)   
Quoi : Cr√©ation automatis√©e de toutes les tables n√©cessaires dans Snowflake via Terraform. Cela inclut les tables de donn√©es (RAW, STAGING, GOLD) mais aussi les tables techniques (reprocess_triggers, transformation_logs).     
Pourquoi : L'infrastructure doit exister avant de pouvoir y √©crire des donn√©es. Terraform assure que tout est versionn√© et reproductible entre les environnements.    
R√©sultat : Toutes les tables sont cr√©√©es dans Snowflake avec le bon format (notamment Iceberg pour la gestion de versions).  

Step 3Ô∏è‚É£ : Projet DBT dans Snowflake
Qui : Data Engineer  
Quoi : D√©veloppement et organisation des mod√®les dbt selon une architecture en couches : RAW (sources brutes), STAGING (transformations et matching), GOLD (donn√©es finales enrichies), et DIAGNOSTICS (vues d'analyse).  
Pourquoi : Cette organisation permet de s√©parer clairement les responsabilit√©s : les sources brutes, la logique de matching, les donn√©es consommables, et les outils de surveillance.  
R√©sultat : Structure du projet dbt claire et maintenable, avec tous les mod√®les n√©cessaires au matching des stores.  

Step 4Ô∏è‚É£ : RBAC via Terraform + GitHub Actions  
Qui : Platform Quoi : Configuration des r√¥les et permissions dans Snowflake pour d√©finir qui peut lire/√©crire dans quelles tables. Le d√©ploiement est automatis√© via GitHub Actions √† chaque changement.  
Pourquoi : S√©curit√© et gouvernance. On veut s'assurer que dbt ne peut √©crire que dans STAGING/GOLD, que les utilisateurs m√©tier ne peuvent que lire GOLD, etc.  
R√©sultat : Matrice de permissions configur√©e et automatiquement d√©ploy√©e. Chaque service/utilisateur a exactement les droits n√©cessaires.  

Step 5Ô∏è‚É£ : Publish ID version Iceberg
Qui : Syst√®me automatis√© (CI/CD)  
Quoi : Apr√®s chaque ex√©cution r√©ussie de dbt, Iceberg g√©n√®re automatiquement un snapshot unique (identifiant de version). Ce snapshot est enregistr√© dans une table de registry pour tracer quelle version est active en production.  
Pourquoi : Permet de savoir exactement quelle version des donn√©es est en production, de revenir en arri√®re en cas de probl√®me (rollback), et d'auditer l'historique des changements.  
R√©sultat : Chaque version des donn√©es est identifi√©e de mani√®re unique et tra√ßable. On peut pointer vers une version sp√©cifique √† tout moment.

Step 6Ô∏è‚É£ : Mise √† jour des views du dossier MART avec le bon commit  
Qui : CI/CD Pipeline  
Quoi : Les vues m√©tier (dans le dossier MART) sont automatiquement mises √† jour pour pointer vers la derni√®re version valid√©e publi√©e √† l'√©tape 5. Ces vues sont consomm√©es par les dashboards et outils analytiques.  
Pourquoi : Les utilisateurs finaux (analystes, dashboards) ne doivent voir que des donn√©es valid√©es et stables. Ils ne doivent jamais pointer directement vers les tables en cours de transformation.  
R√©sultat : Les dashboards et rapports consomment toujours une version stable et valid√©e des donn√©es, sans √™tre impact√©s par les reprocessing en cours.  

Step 7Ô∏è‚É£ : Process des UNMATCHED_STORES (activ√© via Airflow )   
Qui : Job Airflow planifi√© (ex: chaque nuit)  
Quoi : Un job automatique analyse la vue diagnostic qui contient tous les stores non match√©s (GI_ONLY et TH_ONLY) avec leurs candidats potentiels. Pour chaque store ayant un score potentiel int√©ressant (>70), le job cr√©e un "trigger" de reprocessing.  
Pourquoi : D√©tection automatique des probl√®mes de matching. Au lieu d'attendre qu'un humain regarde manuellement, le syst√®me identifie proactivement les cas qui pourraient √™tre am√©lior√©s.  
R√©sultat : Table "reprocess_triggers" aliment√©e automatiquement avec les IDs des stores √† retraiter, prioris√©s selon leur score potentiel.     

Step 7Ô∏è‚É£ **approche** **2** : Process des UNMATCHED_STORES (activ√© via Airflow) - Version Full Refresh  
Qui : Job Airflow planifi√© (ex: chaque nuit)    
R√©sultat : Soit un flag "full_refresh_needed" est activ√© et le prochain run dbt reconstruit toute la table depuis z√©ro avec la logique actuelle, soit le job d√©clenche imm√©diatement un `dbt run --full-refresh` si la situation est critique.   
Toutes les incoh√©rences sont corrig√©es d'un coup, au prix d'un temps de calcul plus long (mais ex√©cut√© de nuit donc transparent pour les utilisateurs).

Step 8Ô∏è‚É£ : User (Analyst) analyse via Streamlit  
Qui : Data Analyst / Data Steward  
Quoi : Un analyste utilise une application Streamlit pour visualiser et comprendre les patterns d'√©chec de matching. Il peut voir les distributions d'erreurs, identifier les causes principales (ex: "40% des √©checs = noms mal normalis√©s"), et explorer les cas individuels.  
Pourquoi : Les m√©triques brutes ne suffisent pas. Un humain doit comprendre pourquoi √ßa ne matche pas pour identifier le bon fix. On deploi√© une app Streamlit par dessus snowlake qui facilite cette analyse exploratoire.  
R√©sultat : L'analyste identifie un pattern clair (ex: les formes juridiques "SAS", "SARL" perturbent le matching) et documente ce qu'il faut corriger.  

Step 9Ô∏è‚É£ : Nouveau commit avec fix sur matching score    
Qui : Data Engineer    
Quoi : Suite √† l'analyse de l'√©tape 8, le DE d√©veloppe un fix (ex: am√©lioration de la normalisation des noms pour retirer les formes juridiques). Il cr√©e une Pull Request avec son changement, qui est test√© automatiquement.  
Pourquoi : Am√©lioration continue du matching. Chaque pattern d'erreur d√©tect√© devient un fix cod√© et versionn√© dans Git.  
R√©sultat : Code am√©lior√© merg√© dans la branche principale, pr√™t √† √™tre d√©ploy√©.    
 
Step 1Ô∏è‚É£0 : Projet DBT (re-triggered)  
Qui : CI/CD Pipeline (Workflow GitHub Actions manag√© par Airflow)   
Quoi : Le merge du code √† l'√©tape 9 d√©clenche automatiquement une nouvelle ex√©cution de dbt. Cette fois, au lieu de tout recalculer, dbt va lire la table "reprocess_triggers" cr√©√©e √† l'√©tape 7 et ne retraiter QUE les stores identifi√©s comme ayant un potentiel d'am√©lioration.
Pourquoi : Efficacit√©. Plut√¥t que de refaire tout le matching sur X pays (co√ªt √©lev√©, temps long), on cible uniquement les cas qui peuvent b√©n√©ficier du fix.
R√©sultat : Reprocessing cibl√© en cours, limit√© au scope d√©fini par les triggers.  

Step 1Ô∏è‚É£1Ô∏è‚É£ : Tables dans Snowflake (en cours de processing)
Qui : Snowflake (ex√©cution des requ√™tes dbt)  
Quoi : Les trois couches de tables (RAW, STAGING, GOLD) travaillent ensemble. RAW contient toujours les sources brutes, STAGING re√ßoit les mises √† jour incr√©mentales via le merge Iceberg (seuls les stores du scope sont recalcul√©s), et GOLD est enrichi avec les nouveaux r√©sultats. Le contexte Terraform observe les m√©triques.  
Pourquoi : Architecture en couches = s√©paration des responsabilit√©s. Chaque couche a son r√¥le : source de v√©rit√© (RAW), logique m√©tier (STAGING), donn√©es consommables (GOLD).  
R√©sultat : Les stores qui √©taient "GI_ONLY" ou "TH_ONLY" sont maintenant correctement match√©s gr√¢ce au fix. Un nouveau snapshot Iceberg est cr√©√©. 

Step 1Ô∏è‚É£2Ô∏è‚É£:Les triggers sont marqu√©s comme "consomm√©s" pour √©viter de les retraiter.  



