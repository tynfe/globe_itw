Welcome to your new dbt project!


![Architecture du pipeline](diagram.svg)


# Cataloguing / Lin√©age / Quality / Monitoring 

voici le lien  https://tynfe.github.io/globe_itw/ des pages de documentation de l'ETL ainsi que le suivi des metrics de tests pour chaque env 
staging ou production qui host: 
- lien de la documentation du projet DBT 
- lien de la page de test / test de qualit√© / freshness / anomalies 


# Globe ITW 
## Vue d‚Äôensemble

Globe ITW est un syst√®me de r√©conciliation et d‚Äôunification de r√©f√©rentiels magasins multi-sources.
Il vise √† construire un r√©f√©rentiel unique et fiable √† partir de deux bases h√©t√©rog√®nes :

GI magasins : source de r√©f√©rence principale
TH magasins : source compl√©mentaire

Le pipeline DBT met en ≈ìuvre un algorithme de matching hybride combinant :  
Similarit√© textuelle (Jaro‚ÄìWinkler sur noms nettoy√©s)  
Proximit√© g√©ographique (distance de Haversine)  
Indexation spatiale via geohash pour acc√©l√©rer la recherche de candidats  

# Architecture DBT ‚Äì Mod√®le Medallion

## Bronze Layer ‚Äì Raw Models (models/raw/)

R√¥le : ingestion et pr√©paration initiale des donn√©es brutes.

Sources trait√©es :
```
raw__gi_stores
raw__th_stores
```

Transformations appliqu√©es :

Standardisation des types de donn√©es  
Normalisation des noms (minuscules, suppression des accents et caract√®res sp√©ciaux)  
G√©n√©ration d‚Äôun hash MD5 pour le matching exact  
Calcul de geohash multi-pr√©cision (150 m / 1200 m)  
Ajout d‚Äôun UUID unique (generated_id)  
Validation des coordonn√©es GPS (latitude ‚àà [-90, 90], longitude ‚àà [-180, 180]) 


## Staging Layer ‚Äì Models (models/staging/)

R√¥le : moteur de matching, historisation et gestion des √©tats.

Mod√®le principal : stg__stores_unified  
Type : table incr√©mentale

### Phase 1 ‚Äì Matching automatique

S√©lection des candidats : magasins partageant le m√™me geohash_1200m 
https://fr.wikipedia.org/wiki/Geohash


```
Calcul du score composite :
+40 : correspondance exacte du hash de nom
+40 : similarit√© Jaro‚ÄìWinkler > 0.8
+20 : distance < 150 m
```

Matching valid√© si score > 80

D√©duplication : conservation du meilleur score par magasin GI

### Phase 2 ‚Äì Classification des magasins

```
Statut	Description
MATCHED	Score > 80, correspondance trouv√©e
GI_ONLY	Magasin GI sans correspondance TH
TH_ONLY	Magasin TH sans correspondance GI
```

### Phase 3 ‚Äì Enrichissement et qualit√©

Flag qualit√© :
````
Flag	Description
PERFECT_MATCH	Score = 100 (hash + distance parfaits)
HIGH_CONFIDENCE	Score ‚â• 95
MEDIUM_CONFIDENCE	Score ‚â• 80
MISSING_IN_TH	Magasin GI sans correspondance
MISSING_IN_GI	Magasin TH sans correspondance
````

D√©tection des changements :
````
Type	Description
INSERT	Nouveau magasin
SCORE_CHANGED	Variation du score
STATUS_CHANGED	Changement de statut MATCHED ‚Üî UNMATCHED
NAME_CHANGED	Nom modifi√©
LOCATION_CHANGED	D√©placement GPS
NO_CHANGE	Aucune modification
````


## Gold Layer ‚Äì Models (models/mart/)

R√©f√©rentiel valid√© des magasins appari√©s avec certitude.

mart__view__matched_stores

````
SELECT store_id, store_name, latitude, longitude
FROM stg__stores_unified
WHERE record_status = 'MATCHED'
````

R√©f√©rentiel des magasins qui n'ont pas de match, vue analytique des magasins non appari√©s.

mart__view__unmatched_stores

Contenu :  
Top 3 des candidats les plus proches (< 5 km)  
D√©tails des scores (nom, distance)   
Diagnostic automatique de l‚Äô√©chec  
Suggestion d‚Äôaction manuelle ou ajustement du seuil


## üîß Macros & utilitaires
````
Macro	Description
calculate_match_score()	Calcule le score composite de matching
diagnose_match_failure()	Analyse la raison d‚Äôun √©chec de matching
suggest_match_action()	Sugg√®re une action corrective
drop_dev_schemas()	Nettoyage automatique des sch√©mas de d√©veloppement
capture_transformation_log_metadata()	Post-hook pour journaliser les transformations
````

# Workflow Git + DBT 

Une fois qu‚Äôun d√©veloppeur a valid√© sa pipeline en environnement de d√©veloppement, il peut pousser ses changements sur la branche staging.

Afin d‚Äô√©viter que plusieurs contributeurs n‚Äôinterf√®rent entre eux sur cet environnement partag√©, chaque d√©veloppement est d‚Äôabord valid√© dans une pipeline annexe, ex√©cut√©e en r√©f√©rence √† l‚Äô√©tat actuel de staging.
Cette √©tape permet de s‚Äôassurer que les nouvelles modifications restent compatibles avec la base stable avant int√©gration.

```
Feature Branch (dev_tyron_ferreira_feature_add_gi_source)
    ‚Üì develop + test isolated
    ‚Üì defer to staging (on build que le model qu'on change par rapport a staging pour eviter de tuer le runner de la ci) 
    ‚Üì 
Staging Branch
    ‚Üì validate + full build
    ‚Üì staging artifacts saved
    ‚Üì
Tag v1.x.x
    ‚Üì deploy to production manuelle declenc√© par une relase + doc 
    ‚Üì cleanup dev schemas
    ‚Üì
Production

Dans Snowflake √ßa donne :
DHW_DEV_TYRON
‚îú‚îÄ‚îÄ ETL                                        ‚Üê Staging (r√©f√©rence stable)
‚îú‚îÄ‚îÄ dev_tyron_ferreira_feature_add_new_source  ‚Üê TON schema isol√©
‚îú‚îÄ‚îÄ dev_ilyas_fix_matching_score               ‚Üê Schema de Ilyas
‚îî‚îÄ‚îÄ dev_ikram_geohash                          ‚Üê Schema de Ikram
```

Une fois la validation effectu√©e, le d√©veloppeur ouvre une Merge Request (MR) vers production.
Cette MR est ensuite relue et approuv√©e par un ou deux reviewers pour garantir la qualit√© et la conformit√© des changements :
https://github.com/tynfe/globe_itw/pulls?q=is%3Apr+is%3Aclosed

Apr√®s validation et fusion sur production, une release est cr√©√©e.
Cette release g√©n√®re automatiquement un tag versionn√©, qui d√©clenche le workflow CI/CD de production.
Ce tag correspond √† la version officiellement d√©ploy√©e en production 
https://github.com/tynfe/globe_itw/actions/runs/19072632369/job/54479368129


un **dashboard** `magasin_analyses` est aussi disponible dans l'onget dashboard du service account pour pouvoir faire une √©tude ad-hoc des matchings 

# ROADMAP 
### V0 

1. Combiner les deux sources pour construire une dimension magasin unique et historis√©e dans le DWH. => **DONE** 
2. Mettre en place un workflow DataOps assurant :
a. Le versionnement et la tra√ßabilit√© du DWH, => **DONE** 
b. Le d√©ploiement automatis√© et s√©curis√© depuis DEV_DWH vers PROD_DWH, => **DONE**
c. La gestion des migrations et le contr√¥le manuel des d√©ploiements en production. => **DONE**
3. Garantir une gouvernance et une s√©curit√© robustes (RBAC) : => **NOT_DONE_BUT_DOCUMENTATION_FOUND**
a. D√©finir une gestion claire des r√¥les et droits d‚Äôacc√®s internes (ex. Data Engineer, Analyst, Product
Owner)


4. Mettre en avant la qualit√©, les tests et l‚Äôobservabilit√© : **=> DONE**
a. Inclure des tests (not_null, unique, relations, custom), **=> DONE**
b. D√©finir des indicateurs de qualit√© de donn√©es (completude, fra√Æcheur, coh√©rence), **=> DONE**

### D√©finir une approche de priorisation entre nouvelles sources, maintenance, dette technique et exigences r√©glementaires,


**1: Produits =>**
regarder le document Roadmap.png 

Axe prioritaire, il r√©pond directement aux besoins clients ou aux retours produits. Ces demandes sont donc trait√©es en top priorit√©.
Plus le volume de demandes sur cet axe est important, plus la bande passante disponible pour l‚Äôaxe 3 (Foundation) diminue.
Cet axe inclut √©galement les am√©liorations continues et la maintenance du produit (par exemple : la source d‚Äôingestion ou les algorithmes de matching).

**2: Data driven d√©cision** 

Cet axe vise √† am√©liorer nos produits et processus en s‚Äôappuyant sur les analyses issues des donn√©es que nous g√©n√©rons.
Il regroupe la d√©finition des KPI de performance, les √©tudes analytiques et les outils de pilotage destin√©s √† d√©mocratiser la culture data au sein de l‚Äôentreprise et √† √©vang√©liser les autres √©quipes √† une approche orient√©e donn√©es.

**3: foundation** 

Il s‚Äôagit de l‚Äôaxe infrastructure et socle technique, garant de la scalabilit√©, de la qualit√© et de la fiabilit√© du Data Platform.
Le sch√©ma d‚Äôarchitecture actuel s‚Äôappuie sur des modules non encore disponibles dans la version 0 (Airflow, RBAC, DDL Terraform√©, etc.).
Cet axe, bien que secondaire dans la priorisation, s‚Äôadapte aux besoins issus des deux autres axes.
Il englobe l‚Äôensemble des sujets infra/scaling/alerting/monitoring/qualit√©, souvent structur√©s sous forme d‚Äôepics, et constitue la base de notre future Data Platform.

### Expliquer comment prioriser les d√©veloppements et d√©ploiements dans un contexte de forte demande m√©tier,

regarder le documetn epic.png  

[TEAM OBJECTIF] => indicateur de r√©ussite pour valider => [ LIST d'EPICs ]  
[EPIC ] => 1 famille de task   
[ TASK ] => unit√© la plus petite repr√©sentant une tache     


# Lien utile 

la solution RBAC cr√©ation de droit et set up des DDL (num√©ro 1)
https://medium.com/snowflake/snowflake-ci-cd-explained-automating-object-creation-with-terraform-dbt-and-github-8c2e38b70ec6  
a trigger via https://cli.github.com/manual/gh_workflow_run  

https://github.com/Infostrux-Solutions/terraform-snowflake-rbac-infra  
https://github.com/Infostrux-Solutions/terraform-snowflake-rbac  
https://github.com/Infostrux-Solutions/terraform-snowflake-database  
https://github.com/Infostrux-Solutions/terraform-snowflake-rbac-infra  
https://github.com/Infostrux-Solutions/terraform-snowflake-warehouse  

Data quality 
https://medium.com/@sdezoysa/tackling-data-quality-challenges-using-data-metric-functions-in-snowflake-a62593effbc6  
https://xebia.com/blog/monitoring-dbt-model-and-test-executions-using-elementary-data/  

CI/CD 
https://nolanbconaway.github.io/blog/2023/my-dbt-continuous-integration-setup.html pour la partie dev to staging  
https://medium.com/@lucasrbarbosa/snowflake-data-platform-episode-ii-deep-dive-dbt-projects-with-github-actions-on-snowflake-615126a6fc35 pour l'env staging / prod  

airflow / cosmos & DBT pour le schema de la roadmap 
https://www.snowflake.com/en/developers/guides/data-engineering-with-apache-airflow/#creating-a-dag-with-cosmos-and-snowpark  
https://github.com/astronomer/astronomer-cosmos  
